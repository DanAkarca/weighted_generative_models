{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of a weighted generative model\n",
    "An example weighted generative model implementation\n",
    "To do:\n",
    "1. Put the new optimiser into the genreative model // review current implementation\n",
    "2. Implement Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_genereative_model conda environment\n",
    "# import requirements\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "import networkx as nx\n",
    "import bct as bctpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import copy\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import brainconn as bct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set network variables\n",
    "nnode = 40 # number of nodes\n",
    "xnode = 10 # x axis\n",
    "ynode = 2 # y axis\n",
    "znode = 2 # z axis\n",
    "# compute inputs\n",
    "Wtgt = np.tril(np.random.randint(0,100,(nnode,nnode)),-1)\n",
    "Wtgt = (Wtgt+Wtgt.T)\n",
    "threshold, upper, lower = 95,1,0\n",
    "Atgt = np.where(Wtgt>threshold,upper,lower)\n",
    "Aseed = np.zeros((nnode,nnode)) # seed the seed as a random edge that exists\n",
    "#ind = np.argwhere(Atgt)\n",
    "#indedge = ind[random.randrange(len(ind)),:]\n",
    "#Aseed[indedge[0],indedge[1]] = Aseed[indedge[1],indedge[0]] = 1\n",
    "x = np.arange(xnode) # set the x axis\n",
    "y = np.arange(ynode) # set the y axis\n",
    "z = np.arange(znode) # set the z axis\n",
    "c = np.array(np.meshgrid(x,y,z)).T.reshape(-1,3) # placed in a grid\n",
    "d = scipy.spatial.distance.pdist(c)\n",
    "D = scipy.spatial.distance.squareform(d) # euclidean distance matrix\n",
    "m = int(np.size(np.where(Atgt.flat))/2) # number of connections\n",
    "eta = np.array([-2]) # eta parameter\n",
    "gamma = np.array([.5]) # gamma parameter\n",
    "model_type = 'matching' # generative model\n",
    "model_var = 'powerlaw' # wiring equation\n",
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the seed matrix\n",
    "subax1 = plt.subplot(121)\n",
    "plt.imshow(Aseed)\n",
    "plt.xlabel('Node')\n",
    "plt.ylabel('Node')\n",
    "# visualise the target matrix\n",
    "subax1 = plt.subplot(122)\n",
    "plt.imshow(Atgt)\n",
    "plt.xlabel('Node')\n",
    "plt.ylabel('Node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and example binary generative model\n",
    "b = bct.generative.generative_model(Aseed, \n",
    "                     D, \n",
    "                     m, \n",
    "                     eta, \n",
    "                     gamma, \n",
    "                     model_type='matching',\n",
    "                     model_var='powerlaw', \n",
    "                     epsilon=1e-6, \n",
    "                     copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the binary model\n",
    "# plot the outcome\n",
    "plt.figure(figsize=(15,5))\n",
    "subax1 = plt.subplot(131)\n",
    "plt.imshow(Aseed)\n",
    "subax2 = plt.subplot(132)\n",
    "plt.imshow(Atgt)\n",
    "subax2 = plt.subplot(133)\n",
    "plt.imshow(b)\n",
    "# display the number of edges in target and final network as a sanity check\n",
    "m,np.size(np.where(b.flat))//2 # number of connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function of\n",
    "def objective_function(x): # minimise communicability\n",
    "    p = np.reshape(x,(nnode,nnode)) # reshape to a matrix form\n",
    "    q = scipy.linalg.expm(p) # compute the communicability\n",
    "    r = np.sum(q) # commute the total communicability\n",
    "    return 2*r # << review!\n",
    "# add in constraints\n",
    "def constraint1_function(x): # while maintaining strengths \n",
    "    s = np.sum(x)\n",
    "    return -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the old weighted matrix and use this to optimise\n",
    "Wexamp = Wtgt/100\n",
    "plt.imshow(Wexamp)\n",
    "plt.colorbar()\n",
    "print(objective_function(Wexamp.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form the bounds\n",
    "lubnds = (epsilon,1.0) # sets lower and upper bounds\n",
    "bnds = ((lubnds,)*np.power(nnode,2)) # for each weight\n",
    "# from the constraints\n",
    "con1 = {'type':'ineq','fun':constraint1_function} # set constraints\n",
    "cons = [con1] # defines them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the optimizer\n",
    "solution = optimize.minimize(objective_function,b.flatten(),method='SLSQP',\\\n",
    "                             bounds=bnds,constraints=cons)\n",
    "# NOTE - what we are running the optimizer on!\n",
    "# print solution\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the nework and its optimisation\n",
    "plt.figure(figsize=(15,5))\n",
    "y = np.reshape(solution.x,(nnode,nnode))\n",
    "subax1 = plt.subplot(121)\n",
    "plt.imshow(b)\n",
    "plt.title('Simulation')\n",
    "subax2 = plt.subplot(122)\n",
    "plt.imshow(y)\n",
    "plt.title('Optimisation')\n",
    "plt.colorbar()\n",
    "# note that the optimisation plateuas at the number of nodes! \n",
    "# This may give reason to think why we grow networks at all in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the weighted generative model\n",
    "alpha = 100 # set the update rate\n",
    "mi, _, _ = bct.similarity.matching_ind(Aseed) # matching index of the seed\n",
    "Kseed = mi + mi.T # value matrix of the seed\n",
    "Kseed += epsilon # add epsilon\n",
    "mseed = np.size(np.where(Aseed.flat))//2 # compute the number of edges in the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an example generative model\n",
    "if type(model_var) == tuple:\n",
    "    mv1, mv2 = model_var\n",
    "else:\n",
    "    mv1, mv2 = model_var, model_var\n",
    "\n",
    "if mv1 in ('powerlaw', 'power_law'):\n",
    "    Fd = D**eta\n",
    "elif mv1 in ('exponential',):\n",
    "    Fd = np.exp(eta*D)\n",
    "\n",
    "if mv2 in ('powerlaw', 'power_law'):\n",
    "    Fk = Kseed**gamma\n",
    "elif mv2 in ('exponential',):\n",
    "    Fk = np.exp(gamma*Kseed)\n",
    "Ffseed = Fd * Fk * np.logical_not(Aseed)\n",
    "u, v = np.where(np.triu(np.ones((nnode, nnode)), 1)) # get all row column combinations\n",
    "A = copy.deepcopy(Aseed) # set the new variable\n",
    "K = copy.deepcopy(Kseed) # set the new variable\n",
    "Ff = copy.deepcopy(Ffseed) # set the new variable\n",
    "statement = \"From %g seed connections, adding %g connections\" % (mseed,m)\n",
    "print(statement)\n",
    "opt_keep = np.zeros((m-mseed,nopt)) # initialise\n",
    "for ii in range(mseed,m):\n",
    "    C = np.append(0, np.cumsum(Ff[u, v]))\n",
    "    r = np.sum(np.random.random()*C[-1] >= C)\n",
    "    uu = u[r]\n",
    "    vv = v[r]\n",
    "    A[uu, vv] = A[vv, uu] = 1\n",
    "    updateuu, = np.where(np.inner(A, A[:, uu]))\n",
    "    np.delete(updateuu, np.where(updateuu == uu))\n",
    "    np.delete(updateuu, np.where(updateuu == vv))\n",
    "    c1 = np.append(A[:, uu], A[uu, :])\n",
    "    for i in range(len(updateuu)):\n",
    "        j = updateuu[i]\n",
    "        c2 = np.append(A[:, j], A[j, :])\n",
    "\n",
    "        use = np.logical_or(c1, c2)\n",
    "        use[uu] = use[uu+nnode] = use[j] = use[j+nnode] = 0\n",
    "        ncon = np.sum(c1[use]) + np.sum(c2[use])\n",
    "        if ncon == 0:\n",
    "            K[uu, j] = K[j, uu] = epsilon\n",
    "        else:\n",
    "            K[uu, j] = K[j, uu] = (2 / ncon * np.sum(np.logical_and(c1[use],c2[use])) +epsilon)\n",
    "    updatevv, = np.where(np.inner(A, A[:, vv]))\n",
    "    np.delete(updatevv, np.where(updatevv == uu))\n",
    "    np.delete(updatevv, np.where(updatevv == vv))\n",
    "    c1 = np.append(A[:, vv], A[vv, :])\n",
    "    \n",
    "    for i in range(len(updatevv)):\n",
    "        j = updatevv[i]\n",
    "        c2 = np.append(A[:, j], A[j, :])\n",
    "\n",
    "        use = np.logical_or(c1, c2)\n",
    "        use[vv] = use[vv+nnode] = use[j] = use[j+nnode] = 0\n",
    "        ncon = np.sum(c1[use]) + np.sum(c2[use])\n",
    "        if ncon == 0:\n",
    "            K[vv, j] = K[j, vv] = epsilon\n",
    "        else:\n",
    "            K[vv, j] = K[j, vv] = (2 / ncon * np.sum(np.logical_and(c1[use],c2[use])) +epsilon)\n",
    "\n",
    "    Fffinal = Fd * Fk * np.logical_not(A)\n",
    "    \n",
    "    # add an optimisation step\n",
    "    \n",
    "    #com = scipy.linalg.expm(A) # compute communicability\n",
    "    #sumcom = np.sum(com) # sum communicability    \n",
    "    \n",
    "    strength = np.sum(A,axis=1) # get strength\n",
    "    neg_sqrt = np.power(strength,-0.5) # negative sqrt\n",
    "    S = np.diag(neg_sqrt) # diagonalise\n",
    "    X = S.dot(A).dot(S) # form power term\n",
    "    X = np.nan_to_num(X,nan=0) # ensure no nan values\n",
    "    com = scipy.linalg.expm(X) # normalised communicability\n",
    "    sumcom = np.sum(com) # sum normalised communicability\n",
    "    opt_keep[ii] = sumcom\n",
    "    for j in range(nopt): # nopt number of optimisation steps\n",
    "        grad = np.gradient(A,sumcom) # compute the gradient\n",
    "        W = A + alpha*grad[1] # walk down the gradient\n",
    "        W[W<0] = 0 # limit to optimise positive weights\n",
    "print('Simulation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the outcome\n",
    "plt.figure(figsize=(15,15))\n",
    "subax1 = plt.subplot(321)\n",
    "plt.imshow(Aseed)\n",
    "subax2 = plt.subplot(322)\n",
    "plt.imshow(Ffseed)\n",
    "subax3 = plt.subplot(323)\n",
    "plt.imshow(A)\n",
    "subax4 = plt.subplot(324)\n",
    "plt.imshow(Fffinal)\n",
    "subax5 = plt.subplot(325)\n",
    "plt.imshow(W)\n",
    "subax6 = plt.subplot(326)\n",
    "plt.hist(W[W>0])\n",
    "plt.xlabel('Weight, w')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Weight distribution')\n",
    "subax6.spines['top'].set_visible(False)\n",
    "subax6.spines['right'].set_visible(False)\n",
    "# display the number of edges in target and final network as a sanity check\n",
    "m,np.size(np.where(A.flat))//2 # number of connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
